---
title: "New York Yellow Cabs Data Analysis"
author: "Kimia Khaffafzadeh Ahrabi, Amir Nejat, Tarek Halabi"
date: "5/16/2020"
output: html_document
---
Introduction: 

The dataset we have worked on belongs to the yellow taxi cabs that operate in New York. We chose October 2018 data to analyze and try to see if we can learn more about the commute new yorkers experience on a daily basis. 

We began by setting up and cleaning the data, only selecting our desired attributes.
The mentioned dataset had 8 million entries so we took a random sample of 2 million entries to work with. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gapminder)
library(broom)
library(ggplot2)
library(tidyverse)
library(stringr)
library(leaflet)
library(dplyr)
library(lubridate)
library(chron)
library(caret)
library(plotROC)
library(pracma)
```

```{r cleaningdata}
url <- "https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-10.csv"
taxi_tab <- read_csv(url)
head(taxi_tab)
```

```{r sampling}

taxi_tab <- taxi_tab %>%
  sample_n(2000000) %>%
  select(VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, fare_amount, tip_amount, tolls_amount, PULocationID, DOLocationID)
head(taxi_tab)

```

The data set includes the drop off and pickup location. However, it has used location identification number to specify different zones in New York. We found a helpful table mentioning which borough of New York these IDs refer to. 

``` {r zonetab}
zoneurl <- "https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
zone_tab <- read_csv(zoneurl)
head(zone_tab)
```

We now join our existing data set with this new table so that we can see to which burough of New York every ride entry belongs to. 

```{r mergezonenames}
  zone_df <- taxi_tab %>% full_join(zone_tab, by=c("PULocationID"="LocationID")) %>%
  select(-Zone, -service_zone)
  head(zone_df)

```

Since the dataset we had only included datetime attributes and we wanted to work with trends that would occur throughout the days of the week, we decided to add an extra attribute called 'day' that would show which day of the week that date was. The code below is showing this. 

```{r addingdays}

  split <- taxi_tab$tpep_dropoff_datetime
  split<-as.data.frame(split)
  split<- split%>%separate(split, c("date","time"), sep="\\s" )
  split$day <- weekdays(as.Date(split$date))
  taxi_tab$day <-split$day
  
```

We also added the same attribute to the dataframe that includes boroughs' names.

```{r graphzones}

split <- zone_df$tpep_dropoff_datetime
  split<-as.data.frame(split)
  split<- split%>%separate(split, c("date","time"), sep="\\s" )
  split$day <- weekdays(as.Date(split$date))
  zone_df$day <-split$day 
zone_df
```

The chunk of code below gets the count of rides happening on days of the week, filtering out NA days and Unknown boroughs so that we have a more consistent and clean look at our data. 

```{r getcount}
newdf <- zone_df %>%
  group_by(day,Borough) %>%
  summarise(count=n()) %>%
  filter(!is.na(day)) %>%
  filter(!(Borough=="Unknown"))
head(newdf)
```

The number of rides in Manhatten is much higher than in the other buroughs. To be precise, out of our 2 million entry sample, 1.8 million belongs to this area and because of this significant difference, comparing counts of rides with other buroughs throughout the week causes our graph not to be that useful. We will basically see the trend in Manhattan clearly, but we will not be able to have any useful observation in regards to the other buroughs. Below we have singled out Manhattan rides. The graph is showing the number of rides that happen in this area (to be specific, picked up in this area) and how they change as the week goes by.

```{r sth}
man_df<- newdf %>%
  filter(Borough=="Manhattan") %>%
  group_by(day) %>% 
  summarise(rides=sum(count))

#Arranging weekdays so that they are in the correct order when visualizing our data

man_df$day<- factor(man_df$day, levels=c("Monday",
    "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday","Sunday"))
man_df<-man_df[order(man_df$day),]

man_df %>%
  ggplot(aes(x=day, y=rides, fill=day))+geom_bar(stat = "identity")+ggtitle(label = "Weekday Ride Number Comparison")+theme_minimal()+theme(plot.title = element_text(hjust = 0.5, lineheight = 0.8, face = "bold"))+xlab("Days")+ylab("Number of Rides")
man_df
           
```
What can be observed is that the number of rides is the highest on Wednesdays and lowest on Sundays and Saturdays. 

Another interesting observation is how the duration of rides might change throughout the week. Do newyorkers spend more time riding taxis on the weekend or do the majority use taxis to commute perhaps to and from work? 
Below we are adding the trip_duration attribute to our dataset. 

```{r addingduration}
 split2 <- taxi_tab$tpep_pickup_datetime
 split2 <- taxi_tab$tpep_dropoff_datetime
 split2<-as.data.frame(split2)
 split2$pickup <- taxi_tab$tpep_pickup_datetime
 split2 <- split2%>%separate(split2, c("date_drop","time_drop"), sep="\\s" )
 split2 <- split2%>%separate(pickup, c("date_pickup","time_pickup"), sep="\\s" )
 split2$drop_in_mins <- 60 * 24 * as.numeric(times(split2$time_drop))
 split2$pickup_in_mins <- 60 * 24 * as.numeric(times(split2$time_pickup))
split2$trip_duration <- split2$drop_in_mins - split2$pickup_in_mins
 taxi_tab$trip_duration <- split2$trip_duration
  
```

Now we graph the relationship the days of the week have with the trip durations. 

```{r graphduration}

dur_df<- taxi_tab %>%
  group_by(day) %>% 
  filter(trip_duration>0) %>%
  summarise(avgdur=mean(trip_duration)) 

dur_df$day<- factor(dur_df$day, levels=c("Monday",
    "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday","Sunday"))
dur_df<-dur_df[order(dur_df$day),]

dur_df

```

```{r p2}
dur_df %>%
  ggplot(aes(x=day, y=avgdur))+geom_bar(stat = "identity")+ggtitle(label = "Weekday Trip Duration Comparison")+theme_minimal()+theme(plot.title = element_text(hjust = 0.5, lineheight = 0.8, face = "bold"))+xlab("Days")+ylab("Number of Rides")
dur_df
```

We see that in the middle of the week New Yorkers are spending longer times insinde the cabs which confirms our first graph as well. 


Hypothesis testing(day of the week vs tipping):

Linear regression Model, We are trying to figure out the relationship between day of the week and the tip amount.For the linear regression model to actually be usable the mean should be very zero (or very close). In our case the mean is an extremely small value that it holds true.
null hypothesis: there is no relationship between them. Alternative hypothesis, is there is a relationship between tip amount and day. If the value of the intercept <0.05  it rejects the null hypothesis. If the value of p is greater > 0.05 it does not reject the null hypothesis, meaning that there is no relationship. Even though the p-value is less than 0.05 and the mean of the residuals is close to 0. through the graph and collected data, we did not see a linear regression relationship between these two variables. So we did not feel comfortable using the Linear regression model because some of the assumptions are not met. 


Pre-analysis Thought-process: Before testing the relationship between the day of the week and tipping, we thought we would write up what we thought of the relationship. We came to an agreement, saying that the tip percentage will be higher on the weekend than the weekdays. We considered the lifestyle of people in New York and believed that people are more likely to go out of their routine schedule(rather than using their daily transportation to go to work) and be willing to spend more money. In spending more money, we thought this would translate over to tipping taxi drivers. With that, we start our analysis:

Linear regression Model, We are trying to figure out the relationship between Day of the week and the Tip amount. For the linear regression model to actually be using the mean should be very zero (or very close). In our case, the mean is an extremely small value that it holds true.

null hypothesis: there is no relationship between them. The alternative hypothesis: is there is a relationship between tip amount and day. If the value of the intercept is less than 0.05 it rejects the null hypothesis. If the value of p is greater than 0.05, it does not reject the null hypothesis, meaning that there is no relationship. We were also able to identify the mean of the residuals as -9.138805e-17 which passes the assumption that the mean of the residuals needs to be very close to 0 for it to be a possible linear regression relationship.

Scatter plot below is showing Days of the Week vs Dist. Travelled 

```{r scatterplot}

taxi_tab$day<- factor(taxi_tab$day, levels=c("Monday",
    "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday","Sunday"))
viewtaxi_tab<-taxi_tab[order(taxi_tab$day),]


taxi_tab %>% ggplot(aes(x = day, y = trip_distance))+ geom_point() + labs(title = "Day of the Week Vs Distance Travelled")
```


Using a boxplot to find a relationship between tipping habits and day of the week, we cannot easily identify any obvious trends with the eye test, To take a deeper look towards the data itself, We decided it would be good to create the Further_Testing table to get more exact values.


```{r furthertesting}
    Further_testing <- taxi_tab%>% group_by(day) %>% summarize(avg_fare = mean(fare_amount), avg_tip = mean(tip_amount), sum_fare = sum(fare_amount), sum_tip = sum(tip_amount), Count = n() )
  Further_testing
```

we can observe that from the percent tip from the overall payment it is slightly smaller on the weekends. That along with not being able to reject the null hypothesis because the p-value is <0.05 and the mean of the residual very close to 0 pushes us to further analyze this relationship. Using this sample, We tidy our residuals to get a better sense of the data. We get clear estimates that Saturday and Sunday see the least tip amounts from any day.

Post-Analysis: Given this information, We can safely assume that there is analytical proof that there is a relationship between the tip amount and whether it’s a weekend/weekday. We see that our pre-analysis assumptions regarding this relationship were incorrect and in fact, the opposite was true. A taxi driver is more likely to get a better tip on a weekday than a weekend.

For further information visit:  "http://r-statistics.co/Assumptions-of-Linear-Regression.html"


Now we will graph the boxplot.

```{r boxplot}
  
  # box plot representing tip amounts compared to the day
  taxi_tab %>% 
  filter(tip_amount>=0) %>%
  ggplot(aes(x = day, y = tip_amount))+ geom_boxplot() + geom_smooth(method = lm)+ labs(title = "Day of the Week Vs Tip amount")
  
```


```{r hyptest3}

  get_resid <- lm(tip_amount~day, data = taxi_tab)
  #checking the mean of the residuals
  mean(get_resid$residuals)
  
  get_resid_tidy <- get_resid %>% tidy() 
  
  augment_lm <- get_resid %>%augment()
  
  augment_lm %>% ggplot(aes(x=day, y =.resid)) +geom_violin() + geom_smooth(method = lm)+ labs(title = "Residuals vs year", x ="day", y = "residual")
  
  get_resid_tidy %>% knitr :: kable()

  augment_lm %>% ggplot(aes(x =factor(.fitted), y =.resid)) +geom_violin() + geom_smooth()+ labs(title = "Residuals vs fitted", x =" fitted", y = "residual")

```


Taxi information for November of 2018. This is a secondary data set needed for our machine learning part of the project. 

```{r gettingnovdata}
url <- "https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-11.csv"
taxi2 <- read_csv(url)
```


Before we start the prediction task analysis, we need to combine the two datasets to make a comparison between the months of October and November. 

```{r combine}
taxi1 <- taxi_tab %>%
    select(tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, fare_amount, tip_amount, tolls_amount, PULocationID, DOLocationID) 
taxi2 <- taxi2 %>%
  sample_n(2000000) %>%
    select(tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, fare_amount, tip_amount, tolls_amount, PULocationID, DOLocationID) 

total <- rbind(taxi1, taxi2)
head(total)
```


The prediction task that we are going to respond is:

Can we predict if the tip amount will increase or decrease one month from now?

We are going to use machine learning to answer this question. Even though there are many different methods of machine learning, the method that we are going to use is a random forest with 50 tress. Here is a link to explore different methods of machine learning in R:
https://machinelearningmastery.com/machine-learning-in-r-step-by-step/ This website has interesting info on machine learning and explains how to use each method. 

First, we will compare the tip-amount for October to November label it as up or down depending on the sign of the difference. The difference would be October - November. In order to do that, we will extract the date from date and time. Then, we extract day and year from date. Lastly, we create the direction varible based on the value of diff, so If the difference is negative, the direction would be up, otherwise the direction would be down. 



```{r machine learning}
   total$my <- format(as.Date(total$tpep_pickup_datetime,format="%Y-%m-%d"), format = "%m") 
   total$my <- as.numeric(total$my) 
   total$yy <- format(as.Date(total$tpep_pickup_datetime,format="%Y-%m-%d"), format = "%Y") 
   total$yy <- as.numeric(total$yy) 
   
   total <- mutate(total, dm = my + yy*1000) 
   
   
   wp <- total %>%
   drop_na() %>%
   filter(dm  %in% c("2018010", "2018011")) %>%
   select(PULocationID, dm, tip_amount) %>%
   distinct(PULocationID, dm, .keep_all = TRUE) %>%
   spread(dm, tip_amount)
   names(wp)[names(wp) == "2018010"] <- "October"
   names(wp)[names(wp) == "2018011"] <- "November"
   
   
   wp <- mutate(wp, diff = November - October) 
   wp <- mutate(wp, Direction = ifelse(diff>0, "up", "down"))
   wp <- select(wp, PULocationID, Direction)
   
   head(wp)


```

In order to train our model, we tidy the data into a wide dataset using the tidyr::spread function, then we create a data frame that shows the differences for each day in the month of Octobor. This table will be used later in our code.


```{r spreading data}

taxi_tab$tpep_pickup_datetime <- as.Date(taxi_tab$tpep_pickup_datetime)
wide_df <- taxi_tab %>%
  select(  PULocationID, tpep_pickup_datetime , tip_amount) %>%
     distinct(PULocationID, tpep_pickup_datetime, .keep_all = TRUE) %>%
  tidyr::spread(tpep_pickup_datetime, tip_amount)%>%
  select(1,5:35)
wide_df[is.na(wide_df)] <- 0.00
head(wide_df)
```
Now we create a matrix from the wide dataset then we inner join the new matrix with wp dataset(which gives the direction )


```{r matrix}
matrix <- wide_df %>%
  as.matrix()

ab_df <- matrix%>%
  magrittr::set_colnames(NULL) %>%
  as_data_frame() %>%
  mutate(PULocationID= wide_df$PULocationID)
  
final_df <- ab_df %>%
  inner_join(wp %>% select(PULocationID, Direction), by="PULocationID") %>%
  mutate(Direction=factor(Direction, levels=c("down", "up")))%>%
  select(-PULocationID) %>%
  na.omit()

head(final_df)
```


The pervious codes were performed to get the necessary information to the test. This is the most important part of the machine learning, which is running the test to make the prediction. We will use 10-fold cross-validation to find out how many mtry is enough to give a decent prediction. Since the data set is big, we are using 10-fold-cross validation to make the validation sets have more examples.

https://machinelearningmastery.com/machine-learning-in-r-step-by-step/ 

```{r test part}
set.seed(1234)

cv_partition <- createFolds(final_df$Direction,
                            k=10, returnTrain = TRUE)

fit_control <- trainControl( 
  method = "cv",
  number = 10,
  index = cv_partition,
  #indexOut = cv_partition,
  summaryFunction=twoClassSummary,
  classProbs=TRUE,
  savePredictions=TRUE)


fit <- train(Direction~.,
                    data= final_df,
                    method = "rf",
                    ntree = 50,
                    trControl = fit_control,
                    metric="ROC")

fit
```



``` {r Roc Curve}
curve_df <-
  fit$pred %>%
    filter(mtry == 32)

curve_df %>%
  ggplot(aes(m=up,d=factor(obs, levels=c("up","down")))) +
    geom_roc() +
    coord_equal() +
    style_roc() 

```

Based on the roc curve, we can see the our curve is very similar to the diagonal line in terms of shape. This indicates that our test is useless and it cannot be used to predict the tip amount of one month based on the previous month.


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
